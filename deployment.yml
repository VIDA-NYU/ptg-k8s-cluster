apiVersion: apps/v1
kind: Deployment
metadata:
  name: ptg-k8s-project
  labels:
    app: ptg-k8s-project
    source: hsrn-tutorial
spec:
  # Run two copies of the Pod
  replicas: 1
  # Perform rolling updates, starting containers before stopping the old ones
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      # This is how the Deployment recognizes its Pods, has to match the labels
      # of the Pod template
      app: ptg-k8s-project
  template:
    metadata:
      labels:
        app: ptg-k8s-project
    spec:
      # affinity:
      #   nodeAffinity:
      #     requiredDuringSchedulingIgnoredDuringExecution:
      #       nodeSelectorTerms:
      #         - matchExpressions:
      #           - key: nvidia.com/gpu.product
      #             operator: In
      #             values:
      #               # One of those GPUs
      #               - "NVIDIA-A100-80GB-PCIe"
      #               - "Quadro-RTX-8000"
      volumes:
      # This section describes the Pod's volumes
      # Those volumes can be mounted by containers, below
      - name: persistent-data
        persistentVolumeClaim:
          claimName: data-volume
      containers:
        # Here's our Flask container
        - name: argus-rt
          # image: ttl.sh/hsrn-flask-clock
          image: ghcr.io/vida-nyu/tim-dashboard:demo-november-2023-apiurl
          ports:
            # This is the port we'll expose to the internet eventually
            - name: web
              # containerPort: 5000
              containerPort: 80
          imagePullPolicy: Always
          # resources:
          #   requests:
          #     cpu: 10m # Request very little CPU
          #     memory: 100Mi # Request that this memory be allocated to us
          #   limits:
          #     cpu: 100m # Throttle the container if using more CPU
          #     memory: 100Mi # Terminate the container if using more memory
        - name: api
          image: scastelo/my_apiserver_image:firsttry
          # image: ghcr.io/vida-nyu/ptg-api-server:main
          command: [ "python" ]
          args: [ "-m", "gunicorn", "main:app", "-w", "4", "-k", "uvicorn.workers.UvicornWorker", "-b", "0.0.0.0:8000" ]
          ports:
            # This is the port we'll expose to the internet eventually
            - name: web
              containerPort: 8000
          env:
            - name: REDIS_URL
              value: redis://localhost:6379
            - name: MONGO_URL
              value: mongodb://localhost:27017
          volumeMounts:
            # This section indicates where to mount the Pod's volumes
            - name: persistent-data
              mountPath: /data/recordings
          imagePullPolicy: Always
          # resources:
          #   requests:
          #     cpu: 10m # Request very little CPU
          #     memory: 100Mi # Request that this memory be allocated to us
          #   limits:
          #     cpu: 100m # Throttle the container if using more CPU
          #     memory: 100Mi # Terminate the container if using more memory
        - name: redis
          image: redis
          ports:
            - name: web
              containerPort: 6379
          env:
            - name: ALLOW_EMPTY_PASSWORD
              value: 'yes'
          imagePullPolicy: Always
          # resources:
          #   requests:
          #     cpu: 10m # Request very little CPU
          #     memory: 100Mi # Request that this memory be allocated to us
          #   limits:
          #     cpu: 100m # Throttle the container if using more CPU
          #     memory: 100Mi # Terminate the container if using more memory
        - name: mongo
          image: mongo:latest
          ports:
            - name: web
              containerPort: 27017
          env:
            - name: MONGODB_INITDB_ROOT_USERNAME
              value: admin
            - name: MONGODB_INITDB_ROOT_PASSWORD
              value: admin
          imagePullPolicy: Always
          # resources:
          #   requests:
          #     cpu: 10m # Request very little CPU
          #     memory: 100Mi # Request that this memory be allocated to us
          #   limits:
          #     cpu: 100m # Throttle the container if using more CPU
          #     memory: 100Mi # Terminate the container if using more memory
        # - name: mongo-express
        #   image: mongo-express
        #   ports:
        #     - name: web
        #       containerPort: 8081
        #   env:
        #     - name: ME_CONFIG_MONGODB_SERVER
        #       value: localhost
        #     - name: ME_CONFIG_MONGODB_ADMINUSERNAME
        #       value: admin
        #     - name: ME_CONFIG_MONGODB_ADMINPASSWORD
        #       value: admin
        #     - name: ME_CONFIG_BASICAUTH_USERNAME
        #       value: admin
        #     - name: ME_CONFIG_BASICAUTH_PASSWORD
        #       value: admin
        #   # resources:
        #   #   requests:
        #   #     cpu: 10m # Request very little CPU
        #   #     memory: 100Mi # Request that this memory be allocated to us
        #   #   limits:
        #   #     cpu: 100m # Throttle the container if using more CPU
        #   #     memory: 100Mi # Terminate the container if using more memory
        - name: perception
          image: ghcr.io/vida-nyu/ptg-server-ml-perception:main
          command: [ "python" ]
          args: ["main_states.py", "run"]
          ports:
            # This is the port we'll expose to the internet eventually
            - name: web
              containerPort: 8265
          env:
            - name: PYTHONUNBUFFERED
              value: "1"
          volumeMounts:
            # This section indicates where to mount the Pod's volumes
            - name: persistent-data
              mountPath: dev/shm
            - name: persistent-data
              mountPath: /src/app/models
              # subPath: /data/models
            - name: persistent-data
              mountPath: /root/.cache
              # subPath: /data/models/cache
            - name: persistent-data
              mountPath: /root/.torch/iopath_cache
              # subPath: /data/models/torch_iocache

          imagePullPolicy: Always
          resources:
              limits:
                nvidia.com/gpu: 1 # Request 1 NVIDIA GPU
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
      imagePullSecrets:
        - name: regcred
