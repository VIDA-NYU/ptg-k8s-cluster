apiVersion: apps/v1
kind: Deployment
metadata:
  name: ptg-k8s-project
  labels:
    app: ptg-k8s-project
    source: hsrn-tutorial
spec:
  # Run two copies of the Pod
  replicas: 1
  # Perform rolling updates, starting containers before stopping the old ones
  strategy:
    type: Recreate
    # rollingUpdate:
    #   maxSurge: 1
    #   maxUnavailable: 0
  selector:
    matchLabels:
      # This is how the Deployment recognizes its Pods, has to match the labels
      # of the Pod template
      app: ptg-k8s-project
  template:
    metadata:
      labels:
        app: ptg-k8s-project
    spec:
      # affinity:
      #   nodeAffinity:
      #     requiredDuringSchedulingIgnoredDuringExecution:
      #       nodeSelectorTerms:
      #         - matchExpressions:
      #           - key: nvidia.com/gpu.product
      #             operator: In
      #             values:
      #               # One of those GPUs
      #               - "NVIDIA-A100-80GB-PCIe"
      #               - "Quadro-RTX-8000"
      volumes:
        # This section describes the Pod's volumes
        # Those volumes can be mounted by containers, below
        - name: persistent-data
          persistentVolumeClaim:
            claimName: data-volume
        - name: shm
          emptyDir:
            medium: Memory
      containers:
        # Here's our Flask container
        - name: argus-rt
          # image: ttl.sh/hsrn-flask-clock
          image: ghcr.io/vida-nyu/tim-dashboard:demo-november-2023-apiurl
          ports:
            # This is the port we'll expose to the internet eventually
            - name: web
              # containerPort: 5000
              containerPort: 80
          imagePullPolicy: Always
        # - name: argus-2
        #   # image: ttl.sh/hsrn-flask-clock
        #   image: ghcr.io/vida-nyu/argus2:main
        #   ports:
        #     # This is the port we'll expose to the internet eventually
        #     - name: web
        #       # containerPort: 5000
        #       containerPort: 3000
          imagePullPolicy: Always
          resources:
          #   requests:
          #     cpu: 10m # Request very little CPU
          #     memory: 100Mi # Request that this memory be allocated to us
          #   limits:
          #     cpu: 100m # Throttle the container if using more CPU
          #     memory: 100Mi # Terminate the container if using more memory
        - name: api
          image: scastelo/my_apiserver_image:firsttry
          # image: ghcr.io/vida-nyu/ptg-api-server:main
          command: [ "python" ]
          args: [ "-m", "gunicorn", "main:app", "-w", "4", "-k", "uvicorn.workers.UvicornWorker", "-b", "0.0.0.0:8000" ]
          ports:
            # This is the port we'll expose to the internet eventually
            - name: web
              containerPort: 8000
          env:
            - name: REDIS_URL
              value: redis://localhost:6379
            - name: MONGO_URL
              value: mongodb://localhost:27017
          volumeMounts:
            # This section indicates where to mount the Pod's volumes
            - name: persistent-data
              mountPath: /data/recordings
          imagePullPolicy: Always
          # resources:
          #   requests:
          #     cpu: 10m # Request very little CPU
          #     memory: 100Mi # Request that this memory be allocated to us
          #   limits:
          #     cpu: 100m # Throttle the container if using more CPU
          #     memory: 100Mi # Terminate the container if using more memory
        - name: redis
          image: redis
          ports:
            - name: web
              containerPort: 6379
          env:
            - name: ALLOW_EMPTY_PASSWORD
              value: 'yes'
          imagePullPolicy: Always
          # resources:
          #   requests:
          #     cpu: 10m # Request very little CPU
          #     memory: 100Mi # Request that this memory be allocated to us
          #   limits:
          #     cpu: 100m # Throttle the container if using more CPU
          #     memory: 100Mi # Terminate the container if using more memory
        - name: mongo
          image: mongo:latest
          ports:
            - name: web
              containerPort: 27017
          env:
            - name: MONGODB_INITDB_ROOT_USERNAME
              value: admin
            - name: MONGODB_INITDB_ROOT_PASSWORD
              value: admin
          imagePullPolicy: Always
          # resources:
          #   requests:
          #     cpu: 10m # Request very little CPU
          #     memory: 100Mi # Request that this memory be allocated to us
          #   limits:
          #     cpu: 100m # Throttle the container if using more CPU
          #     memory: 100Mi # Terminate the container if using more memory
        # - name: mongo-express
        #   image: mongo-express
        #   ports:
        #     - name: web
        #       containerPort: 8081
        #   env:
        #     - name: ME_CONFIG_MONGODB_SERVER
        #       value: localhost
        #     - name: ME_CONFIG_MONGODB_ADMINUSERNAME
        #       value: admin
        #     - name: ME_CONFIG_MONGODB_ADMINPASSWORD
        #       value: admin
        #     - name: ME_CONFIG_BASICAUTH_USERNAME
        #       value: admin
        #     - name: ME_CONFIG_BASICAUTH_PASSWORD
        #       value: admin
        #   # resources:
        #   #   requests:
        #   #     cpu: 10m # Request very little CPU
        #   #     memory: 100Mi # Request that this memory be allocated to us
        #   #   limits:
        #   #     cpu: 100m # Throttle the container if using more CPU
        #   #     memory: 100Mi # Terminate the container if using more memory
        - name: perception
          image: ghcr.io/vida-nyu/ptg-server-ml-perception:main
          command: [ "python" ]
          args: ["main_states.py", "run"]
          ports:
            # This is the port we'll expose to the internet eventually
            - name: web
              containerPort: 8265
          env:
            - name: PYTHONUNBUFFERED
              value: "1"
            - name: PTG_URL
              value: "http://127.0.0.1:8000"
            - name: MODEL_DIR
              value: "/src/app/models"
          volumeMounts:
            # This section indicates where to mount the Pod's volumes
            - name: shm
              mountPath: /dev/shm
            - name: persistent-data
              subPath: models
              mountPath: /src/app/models
            - name: persistent-data
              subPath: models/cache
              mountPath: /root/.cache
            - name: persistent-data
              subPath: models/torch_iocache
              mountPath: /root/.torch/iopath_cache
          resources:
              limits:
                nvidia.com/gpu: 1 # Request 1 NVIDIA GPU
          imagePullPolicy: Always
        - name: reasoning
          image: ghcr.io/vida-nyu/ptg-server-ml-reasoning:main
          command: [ "python" ]
          args: ["main.py", "run"]
          env:
            - name: PTG_URL
              value: "http://127.0.0.1:8000"
          volumeMounts:
            # This section indicates where to mount the Pod's volumes
            - name: persistent-data
              subPath: models/reasoning
              mountPath: /src/app/models
            - name: persistent-data
              subPath: models/reasoning/nltk
              mountPath: /usr/share/nltk_data
            - name: persistent-data
              subPath: models/reasoning/spacy
              mountPath: /opt/conda/lib/python3.8/site-packages/en_core_web_lg
            - name: persistent-data
              subPath: models/reasoning
              mountPath: /home/ptg/src/storage/logs/

          imagePullPolicy: Always
        - name: in3d
          image: ghcr.io/vida-nyu/ptg-server-ml-in3d:main
          command: [ "python" ]
          args: ["main.py", "run"]
          env:
            - name: PTG_URL
              value: "http://127.0.0.1:8000"
          imagePullPolicy: Always
        - name: memory
          image: ghcr.io/vida-nyu/ptg-server-ml-3d-memory:main
          command: [ "python" ]
          args: ["main.py", "mem", "run"]
          env:
            - name: PTG_URL
              value: "http://127.0.0.1:8000"
          imagePullPolicy: Always
        - name: 3d-memory-sync
          image: ghcr.io/vida-nyu/ptg-server-ml-3d-memory:main
          command: [ "python" ]
          args: ["main.py", "sync", "run"]
          env:
            - name: PTG_URL
              value: "http://127.0.0.1:8000"
          imagePullPolicy: Always

        # recorders
        - name: raw-recorder
          image: ghcr.io/vida-nyu/ptg-server-ml-record:main
          command: [ "python" ]
          args: ["-m", "ptgprocess.processors.record", "raw", "run", "--continuous"]
          env:
            - name: PTG_URL
              value: "http://127.0.0.1:8000"
          volumeMounts:
            # This section indicates where to mount the Pod's volumes
            - name: persistent-data
              # subPath: data/recordings/raw
              subPath: raw
              mountPath: /src/app/recordings
          imagePullPolicy: Always
        - name: video-recorder
          image: ghcr.io/vida-nyu/ptg-server-ml-record:main
          command: [ "python" ]
          args: ["-m", "ptgprocess.processors.record", "video", "run", "--continuous"]
          env:
            - name: PTG_URL
              value: "http://127.0.0.1:8000"
          volumeMounts:
            # This section indicates where to mount the Pod's volumes
            - name: persistent-data
              # subPath: data/recordings/post
              subPath: post
              mountPath: /src/app/recordings
            - name: persistent-data
              # subPath: data/recordings/raw
              subPath: raw
              mountPath: /src/app/raw
          imagePullPolicy: Always
        - name: audio-recorder
          image: ghcr.io/vida-nyu/ptg-server-ml-record:main
          command: [ "python" ]
          args: ["-m", "ptgprocess.processors.record", "audio", "run", "--continuous"]
          env:
            - name: PTG_URL
              value: "http://127.0.0.1:8000"
          volumeMounts:
            # This section indicates where to mount the Pod's volumes
            - name: persistent-data
              # subPath: data/recordings/post
              subPath: post
              mountPath: /src/app/recordings
            - name: persistent-data
              # subPath: data/recordings/raw
              subPath: raw
              mountPath: /src/app/raw
          imagePullPolicy: Always
        - name: json-recorder
          image: ghcr.io/vida-nyu/ptg-server-ml-record:main
          command: [ "python" ]
          args: ["-m", "ptgprocess.processors.record", "json", "run", "--continuous"]
          env:
            - name: PTG_URL
              value: "http://127.0.0.1:8000"
          volumeMounts:
            # This section indicates where to mount the Pod's volumes
            - name: persistent-data
              # subPath: data/recordings/post
              subPath: post
              mountPath: /src/app/recordings
            - name: persistent-data
              # subPath: data/recordings/raw
              subPath: raw
              mountPath: /src/app/raw
          imagePullPolicy: Always
        - name: pointcloud-recorder
          image: ghcr.io/vida-nyu/ptg-server-ml-record:main
          command: [ "python" ]
          args: ["-m", "ptgprocess.processors.record", "pointcloud", "run", "--continuous"]
          env:
            - name: PTG_URL
              value: "http://127.0.0.1:8000"
          volumeMounts:
            # This section indicates where to mount the Pod's volumes
            - name: persistent-data
              # subPath: data/recordings/post
              subPath: post
              mountPath: /src/app/recordings
            - name: persistent-data
              # subPath: data/recordings/raw
              subPath: raw
              mountPath: /src/app/raw
          imagePullPolicy: Always
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
      imagePullSecrets:
        - name: regcred

